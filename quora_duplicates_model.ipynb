{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quora_duplicates_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samsenko/quora-duplicates/blob/master/quora_duplicates_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "3NETAuLT1iSB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**To do:** Reduce number of Epochs to 60; Reduce dropout rate; Figure out how to load model in less time than it takes to train model\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "Z9DjjMf-2R03",
        "colab_type": "code",
        "outputId": "e5c4039d-da15-4d9e-af55-720668678698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import zlib\n",
        "import glob\n",
        "import os\n",
        "\n",
        "from contextlib import suppress\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.python.keras.layers import Embedding, Input, Activation, Masking, Dense, Dropout, GRU, Bidirectional, BatchNormalization, Lambda, Flatten\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.python.keras.utils import to_categorical\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.python.keras.backend import abs\n",
        "\n",
        "tf.logging.set_verbosity('WARN')\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "else:\n",
        "  TPU_WORKER = None"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "tRUzSHsxBeE6",
        "colab_type": "code",
        "outputId": "48e1de66-a268-4159-e308-c9c6680e24a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id':'1VHycjtP6NcpmPFyXJxMd-XykMG0dTpzj'}) \n",
        "downloaded.GetContentFile('quora_embedded.npz') "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K    1% |▎                               | 10kB 8.6MB/s eta 0:00:01\r\u001b[K    2% |▋                               | 20kB 1.8MB/s eta 0:00:01\r\u001b[K    3% |█                               | 30kB 2.6MB/s eta 0:00:01\r\u001b[K    4% |█▎                              | 40kB 1.9MB/s eta 0:00:01\r\u001b[K    5% |█▋                              | 51kB 2.3MB/s eta 0:00:01\r\u001b[K    6% |██                              | 61kB 2.8MB/s eta 0:00:01\r\u001b[K    7% |██▎                             | 71kB 3.2MB/s eta 0:00:01\r\u001b[K    8% |██▋                             | 81kB 3.6MB/s eta 0:00:01\r\u001b[K    9% |███                             | 92kB 4.1MB/s eta 0:00:01\r\u001b[K    10% |███▎                            | 102kB 3.2MB/s eta 0:00:01\r\u001b[K    11% |███▋                            | 112kB 3.3MB/s eta 0:00:01\r\u001b[K    12% |████                            | 122kB 4.9MB/s eta 0:00:01\r\u001b[K    13% |████▎                           | 133kB 4.9MB/s eta 0:00:01\r\u001b[K    14% |████▋                           | 143kB 9.1MB/s eta 0:00:01\r\u001b[K    15% |█████                           | 153kB 9.2MB/s eta 0:00:01\r\u001b[K    16% |█████▎                          | 163kB 9.2MB/s eta 0:00:01\r\u001b[K    17% |█████▋                          | 174kB 9.1MB/s eta 0:00:01\r\u001b[K    18% |██████                          | 184kB 9.1MB/s eta 0:00:01\r\u001b[K    19% |██████▎                         | 194kB 9.1MB/s eta 0:00:01\r\u001b[K    20% |██████▋                         | 204kB 40.6MB/s eta 0:00:01\r\u001b[K    21% |███████                         | 215kB 10.6MB/s eta 0:00:01\r\u001b[K    22% |███████▎                        | 225kB 10.3MB/s eta 0:00:01\r\u001b[K    23% |███████▋                        | 235kB 10.4MB/s eta 0:00:01\r\u001b[K    24% |████████                        | 245kB 10.4MB/s eta 0:00:01\r\u001b[K    25% |████████▎                       | 256kB 10.4MB/s eta 0:00:01\r\u001b[K    26% |████████▋                       | 266kB 10.0MB/s eta 0:00:01\r\u001b[K    27% |█████████                       | 276kB 10.1MB/s eta 0:00:01\r\u001b[K    29% |█████████▎                      | 286kB 10.2MB/s eta 0:00:01\r\u001b[K    30% |█████████▋                      | 296kB 10.1MB/s eta 0:00:01\r\u001b[K    31% |██████████                      | 307kB 10.3MB/s eta 0:00:01\r\u001b[K    32% |██████████▎                     | 317kB 40.7MB/s eta 0:00:01\r\u001b[K    33% |██████████▋                     | 327kB 45.7MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 337kB 47.5MB/s eta 0:00:01\r\u001b[K    35% |███████████▎                    | 348kB 42.6MB/s eta 0:00:01\r\u001b[K    36% |███████████▋                    | 358kB 42.0MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 368kB 51.4MB/s eta 0:00:01\r\u001b[K    38% |████████████▎                   | 378kB 52.8MB/s eta 0:00:01\r\u001b[K    39% |████████████▋                   | 389kB 53.1MB/s eta 0:00:01\r\u001b[K    40% |█████████████                   | 399kB 53.4MB/s eta 0:00:01\r\u001b[K    41% |█████████████▎                  | 409kB 52.0MB/s eta 0:00:01\r\u001b[K    42% |█████████████▋                  | 419kB 52.1MB/s eta 0:00:01\r\u001b[K    43% |██████████████                  | 430kB 13.9MB/s eta 0:00:01\r\u001b[K    44% |██████████████▎                 | 440kB 12.7MB/s eta 0:00:01\r\u001b[K    45% |██████████████▋                 | 450kB 12.8MB/s eta 0:00:01\r\u001b[K    46% |███████████████                 | 460kB 12.7MB/s eta 0:00:01\r\u001b[K    47% |███████████████▎                | 471kB 12.7MB/s eta 0:00:01\r\u001b[K    48% |███████████████▋                | 481kB 12.7MB/s eta 0:00:01\r\u001b[K    49% |████████████████                | 491kB 12.6MB/s eta 0:00:01\r\u001b[K    50% |████████████████▎               | 501kB 12.5MB/s eta 0:00:01\r\u001b[K    51% |████████████████▋               | 512kB 12.2MB/s eta 0:00:01\r\u001b[K    52% |█████████████████               | 522kB 12.2MB/s eta 0:00:01\r\u001b[K    53% |█████████████████▎              | 532kB 34.8MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▋              | 542kB 46.5MB/s eta 0:00:01\r\u001b[K    55% |██████████████████              | 552kB 51.5MB/s eta 0:00:01\r\u001b[K    57% |██████████████████▎             | 563kB 52.8MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▋             | 573kB 51.7MB/s eta 0:00:01\r\u001b[K    59% |███████████████████             | 583kB 50.8MB/s eta 0:00:01\r\u001b[K    60% |███████████████████▎            | 593kB 52.5MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▋            | 604kB 52.9MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 614kB 59.9MB/s eta 0:00:01\r\u001b[K    63% |████████████████████▎           | 624kB 59.0MB/s eta 0:00:01\r\u001b[K    64% |████████████████████▋           | 634kB 58.0MB/s eta 0:00:01\r\u001b[K    65% |█████████████████████           | 645kB 57.2MB/s eta 0:00:01\r\u001b[K    66% |█████████████████████▎          | 655kB 57.2MB/s eta 0:00:01\r\u001b[K    67% |█████████████████████▋          | 665kB 41.5MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 675kB 12.0MB/s eta 0:00:01\r\u001b[K    69% |██████████████████████▎         | 686kB 11.8MB/s eta 0:00:01\r\u001b[K    70% |██████████████████████▋         | 696kB 11.8MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 706kB 11.9MB/s eta 0:00:01\r\u001b[K    72% |███████████████████████▎        | 716kB 11.9MB/s eta 0:00:01\r\u001b[K    73% |███████████████████████▋        | 727kB 11.9MB/s eta 0:00:01\r\u001b[K    74% |████████████████████████        | 737kB 11.9MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████▎       | 747kB 11.9MB/s eta 0:00:01\r\u001b[K    76% |████████████████████████▋       | 757kB 11.9MB/s eta 0:00:01\r\u001b[K    77% |████████████████████████▉       | 768kB 12.8MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 778kB 53.2MB/s eta 0:00:01\r\u001b[K    79% |█████████████████████████▌      | 788kB 56.9MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▉      | 798kB 57.0MB/s eta 0:00:01\r\u001b[K    81% |██████████████████████████▏     | 808kB 55.8MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▌     | 819kB 54.3MB/s eta 0:00:01\r\u001b[K    83% |██████████████████████████▉     | 829kB 54.0MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▏    | 839kB 52.7MB/s eta 0:00:01\r\u001b[K    86% |███████████████████████████▌    | 849kB 51.0MB/s eta 0:00:01\r\u001b[K    87% |███████████████████████████▉    | 860kB 43.2MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▏   | 870kB 39.6MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▌   | 880kB 38.4MB/s eta 0:00:01\r\u001b[K    90% |████████████████████████████▉   | 890kB 38.0MB/s eta 0:00:01\r\u001b[K    91% |█████████████████████████████▏  | 901kB 37.4MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▌  | 911kB 37.8MB/s eta 0:00:01\r\u001b[K    93% |█████████████████████████████▉  | 921kB 37.3MB/s eta 0:00:01\r\u001b[K    94% |██████████████████████████████▏ | 931kB 37.2MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▌ | 942kB 38.1MB/s eta 0:00:01\r\u001b[K    96% |██████████████████████████████▉ | 952kB 39.4MB/s eta 0:00:01\r\u001b[K    97% |███████████████████████████████▏| 962kB 46.1MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 972kB 48.8MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▉| 983kB 48.2MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 993kB 9.3MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7O1SRx9e3jr9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loaded = np.load('quora_embedded.npz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M422Upw-C83q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "emb1, emb2, targets = loaded['a'], loaded['b'], loaded['c']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "phIYzbhTDrWB",
        "colab_type": "code",
        "outputId": "e6cc6282-02a6-4580-e5c9-571488b4522e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(emb1.shape, emb2.shape, targets[:50000].shape)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 30, 300) (50000, 30, 300) (50000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Gix_BgZI3_Rm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_siamese_model(input_shape):\n",
        "    \"\"\"\n",
        "        Model architecture\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the tensors for the two input questions\n",
        "    left_input = Input(shape = input_shape)\n",
        "    right_input = Input(shape = input_shape)\n",
        "    \n",
        "    # Recurrent Neural Network\n",
        "    model = Sequential()\n",
        "    gru = Bidirectional(\n",
        "        GRU(\n",
        "            256,\n",
        "            dropout=0.2,\n",
        "            recurrent_dropout=0.2,\n",
        "            return_sequences=True,\n",
        "        )\n",
        "    )\n",
        "    norm = BatchNormalization()\n",
        "    dense = Dense(1024)\n",
        "    flatten = Flatten()\n",
        "    \n",
        "    model.add(gru)\n",
        "    model.add(norm)\n",
        "    model.add(flatten)\n",
        "    model.add(dense)\n",
        "    \n",
        "    # Generate the encodings (feature vectors) for the two questions\n",
        "    encoded_l = model(left_input)\n",
        "    encoded_r = model(right_input)\n",
        "    \n",
        "    # Add a customized layer to compute the absolute difference between the encodings\n",
        "    L1_layer = Lambda(lambda tensors:abs(tensors[0] - tensors[1]))\n",
        "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
        "    \n",
        "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
        "    prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
        "    \n",
        "    # Connect the inputs with the outputs\n",
        "    siamese_net = tf.keras.Model(inputs=[left_input,right_input],outputs=prediction)\n",
        "    \n",
        "    #compile model\n",
        "    siamese_net.summary()\n",
        "    siamese_net.compile(\n",
        "      tf.train.AdamOptimizer(learning_rate=0.0001),\n",
        "      loss='binary_crossentropy',\n",
        "      metrics=['accuracy'],\n",
        "    )\n",
        "    \n",
        "    # return the model\n",
        "    return siamese_net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k_1N6-Ii--XN",
        "colab_type": "code",
        "outputId": "32e6a56f-7481-4d8d-8246-8340805ba084",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "cell_type": "code",
      "source": [
        "model = get_siamese_model((30, 300))\n",
        "model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "  model,\n",
        "  strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "    tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4010: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 30, 300)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 30, 300)      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 1024)         16587264    input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 1024)         0           sequential[0][0]                 \n",
            "                                                                 sequential[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        lambda[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 16,588,289\n",
            "Trainable params: 16,587,265\n",
            "Non-trainable params: 1,024\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PsrkAmryD0PS",
        "colab_type": "code",
        "outputId": "6f82deda-5bc5-407d-cd5c-9dff06055081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2213
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "  [emb1, emb2], targets,\n",
        "  validation_split=0.1,\n",
        "  epochs=60,\n",
        "  batch_size=64,\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 5000 samples\n",
            "Epoch 1/60\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "50000/50000 [==============================] - 159s 3ms/sample - loss: 0.7794 - acc: 0.6328 - val_loss: 0.4603 - val_acc: 0.7794\n",
            "Epoch 2/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.5680 - acc: 0.7254 - val_loss: 0.3432 - val_acc: 0.8422\n",
            "Epoch 3/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.4536 - acc: 0.7807 - val_loss: 0.2817 - val_acc: 0.8736\n",
            "Epoch 4/60\n",
            "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.3818 - acc: 0.8227 - val_loss: 0.2375 - val_acc: 0.8932\n",
            "Epoch 5/60\n",
            "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.3317 - acc: 0.8475 - val_loss: 0.1943 - val_acc: 0.9166\n",
            "Epoch 6/60\n",
            "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.2891 - acc: 0.8699 - val_loss: 0.1800 - val_acc: 0.9270\n",
            "Epoch 7/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.2588 - acc: 0.8875 - val_loss: 0.1497 - val_acc: 0.9402\n",
            "Epoch 8/60\n",
            "50000/50000 [==============================] - 71s 1ms/sample - loss: 0.2291 - acc: 0.9020 - val_loss: 0.1286 - val_acc: 0.9490\n",
            "Epoch 9/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.2108 - acc: 0.9119 - val_loss: 0.1175 - val_acc: 0.9562\n",
            "Epoch 10/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.1882 - acc: 0.9219 - val_loss: 0.0979 - val_acc: 0.9598\n",
            "Epoch 11/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.1713 - acc: 0.9287 - val_loss: 0.0909 - val_acc: 0.9634\n",
            "Epoch 12/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.1559 - acc: 0.9373 - val_loss: 0.0834 - val_acc: 0.9648\n",
            "Epoch 13/60\n",
            "50000/50000 [==============================] - 74s 1ms/sample - loss: 0.1449 - acc: 0.9409 - val_loss: 0.0714 - val_acc: 0.9696\n",
            "Epoch 14/60\n",
            "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.1360 - acc: 0.9453 - val_loss: 0.0666 - val_acc: 0.9692\n",
            "Epoch 15/60\n",
            "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.1221 - acc: 0.9517 - val_loss: 0.0613 - val_acc: 0.9748\n",
            "Epoch 16/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.1122 - acc: 0.9551 - val_loss: 0.0523 - val_acc: 0.9790\n",
            "Epoch 17/60\n",
            "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.1069 - acc: 0.9571 - val_loss: 0.0523 - val_acc: 0.9792\n",
            "Epoch 18/60\n",
            "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.1027 - acc: 0.9610 - val_loss: 0.0483 - val_acc: 0.9806\n",
            "Epoch 19/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.0947 - acc: 0.9638 - val_loss: 0.0456 - val_acc: 0.9814\n",
            "Epoch 20/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.0899 - acc: 0.9650 - val_loss: 0.0413 - val_acc: 0.9826\n",
            "Epoch 21/60\n",
            "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.0862 - acc: 0.9670 - val_loss: 0.0384 - val_acc: 0.9840\n",
            "Epoch 22/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.0799 - acc: 0.9696 - val_loss: 0.0360 - val_acc: 0.9850\n",
            "Epoch 23/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.0743 - acc: 0.9717 - val_loss: 0.0329 - val_acc: 0.9864\n",
            "Epoch 24/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.0750 - acc: 0.9719 - val_loss: 0.0269 - val_acc: 0.9868\n",
            "Epoch 25/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.0718 - acc: 0.9728 - val_loss: 0.0241 - val_acc: 0.9878\n",
            "Epoch 26/60\n",
            "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.0667 - acc: 0.9750 - val_loss: 0.0219 - val_acc: 0.9876\n",
            "Epoch 27/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.0664 - acc: 0.9752 - val_loss: 0.0231 - val_acc: 0.9864\n",
            "Epoch 28/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.0599 - acc: 0.9772 - val_loss: 0.0225 - val_acc: 0.9856\n",
            "Epoch 29/60\n",
            "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.0610 - acc: 0.9773 - val_loss: 0.0218 - val_acc: 0.9878\n",
            "Epoch 30/60\n",
            "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.0584 - acc: 0.9778 - val_loss: 0.0230 - val_acc: 0.9864\n",
            "Epoch 31/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.0593 - acc: 0.9775 - val_loss: 0.0239 - val_acc: 0.9860\n",
            "Epoch 32/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.0584 - acc: 0.9780 - val_loss: 0.0206 - val_acc: 0.9876\n",
            "Epoch 33/60\n",
            "50000/50000 [==============================] - 74s 1ms/sample - loss: 0.0520 - acc: 0.9806 - val_loss: 0.0181 - val_acc: 0.9884\n",
            "Epoch 34/60\n",
            "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.0526 - acc: 0.9810 - val_loss: 0.0214 - val_acc: 0.9872\n",
            "Epoch 35/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.0536 - acc: 0.9804 - val_loss: 0.0192 - val_acc: 0.9882\n",
            "Epoch 36/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.0510 - acc: 0.9817 - val_loss: 0.0185 - val_acc: 0.9884\n",
            "Epoch 37/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.0513 - acc: 0.9818 - val_loss: 0.0161 - val_acc: 0.9888\n",
            "Epoch 38/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.0464 - acc: 0.9828 - val_loss: 0.0173 - val_acc: 0.9886\n",
            "Epoch 39/60\n",
            "50000/50000 [==============================] - 71s 1ms/sample - loss: 0.0494 - acc: 0.9817 - val_loss: 0.0164 - val_acc: 0.9890\n",
            "Epoch 40/60\n",
            "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.0455 - acc: 0.9834 - val_loss: 0.0172 - val_acc: 0.9890\n",
            "Epoch 41/60\n",
            "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.0469 - acc: 0.9832 - val_loss: 0.0164 - val_acc: 0.9894\n",
            "Epoch 42/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.0469 - acc: 0.9837 - val_loss: 0.0146 - val_acc: 0.9892\n",
            "Epoch 43/60\n",
            "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.0421 - acc: 0.9848 - val_loss: 0.0167 - val_acc: 0.9888\n",
            "Epoch 44/60\n",
            "50000/50000 [==============================] - 71s 1ms/sample - loss: 0.0442 - acc: 0.9841 - val_loss: 0.0166 - val_acc: 0.9886\n",
            "Epoch 45/60\n",
            "50000/50000 [==============================] - 70s 1ms/sample - loss: 0.0434 - acc: 0.9842 - val_loss: 0.0173 - val_acc: 0.9896\n",
            "Epoch 46/60\n",
            "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.0420 - acc: 0.9847 - val_loss: 0.0171 - val_acc: 0.9896\n",
            "Epoch 47/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.0401 - acc: 0.9856 - val_loss: 0.0191 - val_acc: 0.9892\n",
            "Epoch 48/60\n",
            "50000/50000 [==============================] - 74s 1ms/sample - loss: 0.0389 - acc: 0.9861 - val_loss: 0.0191 - val_acc: 0.9902\n",
            "Epoch 49/60\n",
            "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.0382 - acc: 0.9862 - val_loss: 0.0205 - val_acc: 0.9894\n",
            "Epoch 50/60\n",
            "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.0398 - acc: 0.9863 - val_loss: 0.0248 - val_acc: 0.9898\n",
            "Epoch 51/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.0394 - acc: 0.9865 - val_loss: 0.0215 - val_acc: 0.9888\n",
            "Epoch 52/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.0366 - acc: 0.9871 - val_loss: 0.0268 - val_acc: 0.9886\n",
            "Epoch 53/60\n",
            "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.0391 - acc: 0.9865 - val_loss: 0.0169 - val_acc: 0.9896\n",
            "Epoch 54/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.0372 - acc: 0.9867 - val_loss: 0.0180 - val_acc: 0.9900\n",
            "Epoch 55/60\n",
            "50000/50000 [==============================] - 71s 1ms/sample - loss: 0.0359 - acc: 0.9879 - val_loss: 0.0182 - val_acc: 0.9894\n",
            "Epoch 56/60\n",
            "50000/50000 [==============================] - 71s 1ms/sample - loss: 0.0343 - acc: 0.9883 - val_loss: 0.0220 - val_acc: 0.9900\n",
            "Epoch 57/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.0374 - acc: 0.9877 - val_loss: 0.0218 - val_acc: 0.9902\n",
            "Epoch 58/60\n",
            "50000/50000 [==============================] - 71s 1ms/sample - loss: 0.0345 - acc: 0.9883 - val_loss: 0.0237 - val_acc: 0.9894\n",
            "Epoch 59/60\n",
            "50000/50000 [==============================] - 71s 1ms/sample - loss: 0.0335 - acc: 0.9889 - val_loss: 0.0225 - val_acc: 0.9892\n",
            "Epoch 60/60\n",
            "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.0352 - acc: 0.9884 - val_loss: 0.0220 - val_acc: 0.9896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe522e84ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "CQK4k5HLJLRa",
        "colab_type": "code",
        "outputId": "b40551b4-ddb9-44a5-871b-c9e1d30b3214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "model.save('quora_duplicates_feb20.h5')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tPPkjCTOqAYj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from googleapiclient.discovery import build"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sNePN8NBoSY7",
        "colab_type": "code",
        "outputId": "272b1de9-6f80-4ced-8c24-5db0006df0f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "def save_file_to_drive(name, path):\n",
        "    file_metadata = {\n",
        "      'name': name,\n",
        "      'mimeType': 'application/octet-stream'\n",
        "     }\n",
        "\n",
        "    media = MediaFileUpload(path, \n",
        "                    mimetype='application/octet-stream',\n",
        "                    resumable=True)\n",
        "\n",
        "    created = drive_service.files().create(body=file_metadata,\n",
        "                                   media_body=media,\n",
        "                                   fields='id').execute()\n",
        "\n",
        "    print('File ID: {}'.format(created.get('id')))\n",
        "\n",
        "    return created\n",
        "\n",
        "save_file_to_drive(\"quora_duplicates_feb20.h5\", \"./quora_duplicates_feb20.h5\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ID: 1iX4OMiRN5gzhnau6leZ1Q0uvkxjc9ooS\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '1iX4OMiRN5gzhnau6leZ1Q0uvkxjc9ooS'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "hCpNWQYGuNsc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c03546df-0b8d-4fc9-c419-88f3018b5cde"
      },
      "cell_type": "code",
      "source": [
        "inputs1 = np.array([\"Why is triclosan used in toothpaste?\"]*8)\n",
        "inputs2 = np.array([\"What common toothpaste has triclosan?\"]*8)\n",
        "\n",
        "#!python -m spacy download en_core_web_md\n",
        "#embedding = spacy.load('en_core_web_md')\n",
        "embedding_length = 300\n",
        "max_question_length = 30\n",
        "\n",
        "def embed_question(inputs, max_datapoints):\n",
        "  global embedding_length, max_question_length\n",
        "  embedded_inputs = []\n",
        "  i = 0\n",
        "  errors = 0\n",
        "  for question in inputs:\n",
        "    if i % 1000 == 0:\n",
        "      print(\"i = \", i)\n",
        "    if i == max_datapoints:\n",
        "      break\n",
        "    i += 1\n",
        "    doc = embedding(str(question))\n",
        "    padded = np.zeros((max_question_length, embedding_length))\n",
        "    new_question = np.array([])\n",
        "    for word in doc:\n",
        "      new_question = np.vstack((new_question, word.vector)) if new_question.size else word.vector\n",
        "    try:\n",
        "      padded[:new_question.shape[0]] = new_question\n",
        "    except:\n",
        "      errors += 1\n",
        "      padded[:new_question.shape[0]] = new_question[:max_question_length]\n",
        "    embedded_inputs.append(padded)\n",
        "  embedded_inputs = np.array(embedded_inputs)\n",
        "  print(\"errors: \", errors)\n",
        "  return embedded_inputs\n",
        "\n",
        "emb1 = embed_question(inputs1, 8)\n",
        "emb2 = embed_question(inputs2, 8)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i =  0\n",
            "errors:  0\n",
            "i =  0\n",
            "errors:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pgj11CECvZxg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4d6c2e2-bc99-45da-f9f0-6ef65d80c54c"
      },
      "cell_type": "code",
      "source": [
        "model.predict([emb1, emb2])[0][0] #probability the questions are duplicates"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00048187375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "Dq8YvJCuvsuU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yC6I_wqy5Wrd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yz4PAWH35wP4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nW1uHO0v6JqT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}